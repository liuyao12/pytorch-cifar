{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "cifar10_with_PDE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuyao12/pytorch-cifar/blob/master/cifar10_with_PDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf6nUgErY6Bh",
        "colab_type": "text"
      },
      "source": [
        "# Cifar10 with PDE\n",
        "\n",
        "* As far as I'm aware, a simple and novel architecture of ConvNets (Convolutional Neural Networks) that is readily applicable to any existing ResNet backbone.\n",
        "\n",
        "* The key idea would be hard to come by or justify without viewing ResNet as a partial differential equation (like the heat equation). Traditionally, the standard toolkit for machine learning only includes bits of multi-variable calculus, linear algebra, and statistics, and not so much PDE. This partly explains why ResNet comes on the scene relatively late (2015), and why this enhanced version of ResNet has not been \"reinvented\" by the DL community.\n",
        "\n",
        "* Code based off of https://github.com/kuangliu/pytorch-cifar, and the [official PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) \n",
        "\n",
        "* Questions and comments shall be greatly appreciated [@liuyao12](https://twitter.com/liuyao12) or liuyao@gmail.com\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPeChzrK7iYC",
        "colab_type": "text"
      },
      "source": [
        "A quick summary of ConvNets from a Partial Differential Equations (PDE) point of view. For details, see my [notebook](https://observablehq.com/@liuyao12/neural-networks-and-partial-differential-equations) on observable.\n",
        "\n",
        "neural network | heat equation\n",
        ":----:|:-------:\n",
        "input layer | initial condition\n",
        "feed forward | solving the equation\n",
        "hidden layers | solution at intermediate times\n",
        "output layer | solution at final time\n",
        "convolve with 3×3 kernel | differential operator of order ≤ 2\n",
        "weights | coefficients\n",
        "boundary handling (padding) | boundary condition\n",
        "\n",
        "Basically, classical ConvNets (ResNets) are **linear PDEs with constant coefficients**, and here I'm simply making it **variable coefficients**, with the variables being polynomials of degree ≤ 1, which should theoretically enable the neural net to learn more ways to deform than diffusion and translation (e.g., rotation and scaling)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmUdhteH5N9s",
        "colab_type": "code",
        "outputId": "fdb9e1a1-a178-4b65-a778-468c9263b8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "''' \n",
        "ResNet in PyTorch  https://github.com/kuangliu/pytorch-cifar\n",
        "Reference:\n",
        "    Kaiming He 何恺明, Xiangyu Zhang 张祥雨, Shaoqing Ren 任少卿, Jian Sun 孙剑 (Microsoft Research Asia)\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, channels, stride=1, iterations=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.iterations = iterations\n",
        "        self.X1, self.Y1, self.X2, self.Y2 = None, None, None, None\n",
        "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.conv1x = nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.conv1y = nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.conv2x = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.conv2y = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != self.expansion * channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.expansion * channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x1 += self.twist1(x)       # <===== can manually comment out to compare\n",
        "        x1 = F.relu(self.bn1(x1))\n",
        "        x2 = self.conv2(x1)\n",
        "        x2 += self.twist2(x1)      # <===== can manually comment out to compare\n",
        "        x3 = self.shortcut(x) + self.bn2(x2)\n",
        "        x3 = F.relu(x3)\n",
        "        return x3\n",
        "\n",
        "    def twist1(self, x):\n",
        "        if self.X1 is None:\n",
        "            _, _, h, w = list(self.conv1(x).shape)\n",
        "            self.X1 = torch.from_numpy(np.indices((1,1,h,w), dtype='float32')[3]/w-0.5).to(x.device)\n",
        "            self.Y1 = torch.from_numpy(np.indices((1,1,h,w), dtype='float32')[2]/h-0.5).to(x.device)\n",
        "            with torch.no_grad():\n",
        "                self.conv1.weight /= 3\n",
        "                self.conv1x.weight /= 3\n",
        "                self.conv1y.weight /= 3\n",
        "        return self.X1 * self.conv1x(x) + self.Y1 * self.conv1y(x)\n",
        "\n",
        "    def twist2(self, x):\n",
        "        if self.X2 is None:\n",
        "            _, _, h, w = list(self.conv2(x).shape)\n",
        "            self.X2 = torch.from_numpy(np.indices((1,1,h,w), dtype='float32')[3]/w-0.5).to(x.device)\n",
        "            self.Y2 = torch.from_numpy(np.indices((1,1,h,w), dtype='float32')[2]/h-0.5).to(x.device)\n",
        "            with torch.no_grad():\n",
        "                self.conv2.weight /= 3\n",
        "                self.conv2x.weight /= 3\n",
        "                self.conv2y.weight /= 3\n",
        "        return self.X2 * self.conv2x(x) + self.Y2 * self.conv2y(x)\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, channels, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.XX, self.YY = None, None\n",
        "        self.conv2x = nn.Conv2d(channels, channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.conv2y = nn.Conv2d(channels, channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "        self.conv3 = nn.Conv2d(channels, self.expansion * channels, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != self.expansion * channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.expansion * channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
        "        x2 = self.conv2(x1)\n",
        "        x2 += self.twist(x1)       # <===== can manually comment out to compare\n",
        "        x3 = F.relu(self.bn2(x2))\n",
        "        x3 = self.bn3(self.conv3(x3))\n",
        "        x3 += self.shortcut(x)\n",
        "        x3 = F.relu(x3)\n",
        "        return x3\n",
        "\n",
        "    def twist(self, x):\n",
        "        if self.XX is None:\n",
        "            _, _, h, w = list(self.conv2(x).shape)\n",
        "            self.XX = torch.from_numpy(np.indices((1,1,h,w), dtype='float32')[3]/w-0.5).to(x.device)\n",
        "            self.YY = torch.from_numpy(np.indices((1,1,h,w), dtype='float32')[2]/h-0.5).to(x.device)\n",
        "            with torch.no_grad():\n",
        "                self.conv2.weight /= 3\n",
        "                self.conv2x.weight /= 3\n",
        "                self.conv2y.weight /= 3\n",
        "        return self.XX * self.conv2x(x) + self.YY * self.conv2y(x)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, channels, stride))\n",
        "            self.in_channels = channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = F.avg_pool2d(x, 4)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3,4,6,3])\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3,4,23,3])\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3,8,36,3])\n",
        "\n",
        "\n",
        "net = ResNet50()\n",
        "epoch = 0 \n",
        "lr = 0.1\n",
        "checkpoint = {'acc': 0, 'epoch': 0}\n",
        "history = [{'acc': 0, 'epoch': 0}]\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('device =', device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "net.to(device)\n",
        "print('Testing on a random input:')\n",
        "test = torch.randn(1,3,32,32).to(device)\n",
        "print('INPUT', test.shape)\n",
        "print('OUTPUT', net(test).shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device = cpu\n",
            "Testing on a random input:\n",
            "INPUT torch.Size([1, 3, 32, 32])\n",
            "OUTPUT torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ozKUGgKwcruw",
        "outputId": "f35c1191-0bfb-4436-be1f-2f2f5622f6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 26312683.18it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "182f6eb5-1750-463d-a07d-c6dcd15ed0cd",
        "id": "1RzI4cWWHVlg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Training\n",
        "def train(loss_func, opt):\n",
        "    global history\n",
        "    print('Epoch %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (x, y) in enumerate(trainloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        pred = net(x)\n",
        "        loss = loss_func(pred, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = pred.max(1)\n",
        "        total += y.size(0)\n",
        "        correct += predicted.eq(y).sum().item()\n",
        "    print('train loss: %.3f | acc: %.3f (%d/%d)'\n",
        "        % (train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "    history.append({'epoch': epoch, 'train_loss': train_loss, 'train_acc': 100. * correct / total})\n",
        "\n",
        "def test(loss_func):\n",
        "    global checkpoint, history\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x, y) in enumerate(testloader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = net(x)\n",
        "            loss = loss_func(pred, y)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = pred.max(1)\n",
        "            total += y.size(0)\n",
        "            correct += predicted.eq(y).sum().item()\n",
        "    acc = 100. * correct / total\n",
        "    history[-1]['loss'] = test_loss\n",
        "    history[-1]['acc'] = acc\n",
        "    if acc > checkpoint['acc']:\n",
        "        # print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch\n",
        "        }\n",
        "        checkpoint = state\n",
        "        # if not os.path.isdir('checkpoint'):\n",
        "        #     os.mkdir('checkpoint')\n",
        "        # torch.save(state, './checkpoint/ckpt.pth')\n",
        "        print('test  loss: {:.3f} | acc: {:.2f}  ( {}/{}) (up by {:.2f})'.format(\n",
        "               test_loss / (batch_idx + 1), 100. * correct / total, correct, total,\n",
        "               acc - checkpoint['acc']))\n",
        "    else:\n",
        "        print('test  loss: {:.3f} | acc: {:.2f}  ( {}/{})'.format(\n",
        "            test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "for _ in range(100):\n",
        "    global epoch\n",
        "    if epoch - checkpoint['epoch'] >= 15:\n",
        "        lr *= 0.1\n",
        "        print('learning rate downgraded to {} at epoch {}'.format(lr, epoch))\n",
        "        print('loading state_dict from Epoch {} (acc = {})'.format(checkpoint['epoch'], checkpoint['acc']))\n",
        "        net.load_state_dict(checkpoint['net'])\n",
        "        opt = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    train(loss_func, opt)\n",
        "    test(loss_func)\n",
        "    epoch += 1\n",
        "print('finish at lr =', lr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3R7ZAEEyMUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIDu_XmJErwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ResNet18 = {'run0': [(0, 40.77), (1, 50.38), (2, 60.33), (3, 67.54), (4, 72.53), (5, 74.63), (8, 77.29), (10, 80.53), (14, 81.13), (16, 84.1), (20, 84.58), (29, 85.29), (42, 87.32), (50, 92.76), (51, 93.15), (52, 93.52), (53, 93.64), (54, 93.65), (58, 93.92), (75, 94.05), (76, 94.35), (82, 94.37), (85, 94.38), (86, 94.39), (92, 94.47)],\n",
        "        'run1': [(0, 46.66), (1, 59.49), (2, 64.82), (3, 67.94), (4, 73.07), (5, 76.9), (7, 80.42), (10, 82.33), (12, 83.24), (15, 83.56), (22, 84.14), (31, 84.36), (32, 86.76), (36, 87.09), (50, 92.81), (51, 92.97), (52, 93.31), (53, 93.33), (54, 93.58), (55, 93.61), (58, 93.7), (60, 93.71), (62, 93.72), (64, 93.88), (75, 94.32), (76, 94.47), (77, 94.52), (78, 94.55), (79, 94.56), (80, 94.59), (81, 94.68), (83, 94.74), (85, 94.76), (87, 94.77), (88, 94.82), (99, 94.89)], \n",
        "        'run2': [(0, 53.2), (1, 59.44), (2, 74.87), (4, 77.51), (5, 80.48), (8, 81.88), (13, 82.32), (16, 82.91), (18, 82.99), (19, 83.11), (24, 83.8), (25, 85.36), (28, 86.4), (50, 92.47), (51, 93.07), (52, 93.63), (56, 93.71), (61, 93.77), (63, 93.94), (75, 94.26), (76, 94.41), (77, 94.43), (78, 94.67), (81, 94.81), (84, 94.84)]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7B52zeW88ef",
        "colab_type": "text"
      },
      "source": [
        "### Results on ResNet18: \n",
        "Following kuangliu, I manually change the learning rate as follows:\n",
        "\n",
        "* `lr=0.1` for Epoch [0:50] \n",
        "* `lr=0.01` for Epoch [50:75]\n",
        "* `lr=0.001` for Epoch [75:100]\n",
        "\n",
        "epoch | 0 | 5 |  10 | 15 | 20 | 25 | 30 | 45 | 50 | 55 | 65 | 75 | 80 | 90 | 99\n",
        ":---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:\n",
        "without twist ('run0') | 40.77 | 74.63 | 80.53 | 81.13 | 84.58 | - | 85.29 | 87.32 | 92.76 | 93.65 | - | 94.05 | 94.35 | 94.39 | 94.47\n",
        "with twist | 42.39 | 74.86 | 81.51 | 82.88 | - | 84.34 | 86.98 | 87.85 | 92.34 | 93.65 | - | 93.73 | 94.22\n",
        "with twist ('run1') | 46.66 | 76.90 | 82.33 | 83.56 | - | 84.14 | - | 87.09 | 92.81 | 93.61 | 93.88 | 94.32 | 94.59 | 94.82 | 94.89\n",
        "with twist | 50.56 | 80.40 | 82.81 | 85.15 | - | - | - | 87.36 | 93.20 | 93.84 | 94.02\n",
        "deep twist (3) | 41.55 | 72.37 | 78.81 | 79.49 | 82.38 | 82.38 | 83.14 | 83.36 \n",
        "\n",
        "Not a significant improvement as I initially thought based on the reported accuracy at https://github.com/kuangliu/pytorch-cifar "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMfk2BX43F1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}